---
title: "pipeline to automatically generate ADRG"
---

# Automation block 1: TLG generation information preprocessing

## Read in .r codes, extract information of variables, dataset, output

These information can be used in section 7.3 and 3.1

```{r}
library(httr)
library(jsonlite)
library(readr)
library(here)
library(parallel)


# Set number of cores (e.g., 4 cores)
num_cores <- 4

# Load environment variables from project root .Renviron
readRenviron(here::here(".Renviron"))

source(here::here("pipeline/utils/llm_api.R"))
source(here::here("pipeline/automation/llm_prompts.R"))

#MODEL_NAME <- "claude-3-5-haiku-latest"  # See or add to available models in llm_api.R
MODEL_NAME <- "gpt-4o"
# initial comparison between gpt-4o, deepseek-reasoner, claude. gpt-4o & claude gave more consistent result with cleaner formatting

# Validate model selection
if (!MODEL_NAME %in% names(SUPPORTED_MODELS)) {
  stop(sprintf(
    "Model '%s' not supported. Supported models are: %s",
    MODEL_NAME, paste(names(SUPPORTED_MODELS), collapse = ", ")
  ))
}

# Mark the start of a new run
mark_run_start(sprintf("Starting ADRG generation pipeline with model: %s", MODEL_NAME))

# Print current working directory and model info
print("Current working directory:")
print(here::here())
print(sprintf("Using model: %s (%s)", MODEL_NAME, SUPPORTED_MODELS[[MODEL_NAME]]$provider))

# identify tlg r files - using here package for path management
tlg_r_names <- list.files(path = here::here("submission/programs"), pattern = "^tlf.*\\.r$", full.names = TRUE)

# Print found files
print("Found TLG files:")
print(tlg_r_names)
```



Extract information from R code

```{r, echo=FALSE, results = 'hide'}
tlg_var_dat_pair <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_var_dat_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_filter <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_filter_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_output <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_output_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_parse_dat_var <- sapply(tlg_var_dat_pair, function(i)
  llm_call(paste(prompt_parse_dat_var, i), 
           model = MODEL_NAME))
```

```{r}
tab_out <- cbind(basename(tlg_r_names), tlg_output, tlg_parse_dat_var, tlg_filter)
colnames(tab_out) <- c("script","output","Analysis Datasets & Variables","selection criteria")
rownames(tab_out) <- NULL
knitr::kable(tab_out)

write.csv(tab_out, file="../../outputs/intermediate/tlg_var_filter_table.csv", row.names = FALSE)
```



## read in variable descirptions

These information can be used in section 3.1

# Automation block 2: ADaM generation informtion proprocessing

TBD

# Automation block 3: R env information preprocessing

TBD

# insert information into ADRG template
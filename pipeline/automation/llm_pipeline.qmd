---
title: "pipeline to automatically generate ADRG"
---

# Automation block 1: TLG generation information preprocessing

## Read in .r codes, extract information of variables, dataset, output

These information can be used in section 7.3 and 3.1

```{r}
library(httr)
library(jsonlite)
library(readr)
library(here)

# Load environment variables from project root .Renviron
readRenviron(here::here(".Renviron"))

source(here::here("pipeline/utils/llm_api.R"))
source(here::here("pipeline/automation/llm_prompts.R"))

MODEL_NAME <- "claude-3-7-sonnet-latest"  # See or add to available models in llm_api.R

# Validate model selection
if (!MODEL_NAME %in% names(SUPPORTED_MODELS)) {
  stop(sprintf(
    "Model '%s' not supported. Supported models are: %s",
    MODEL_NAME, paste(names(SUPPORTED_MODELS), collapse = ", ")
  ))
}

# Print current working directory and model info
print("Current working directory:")
print(here::here())
print(sprintf("Using model: %s (%s)", MODEL_NAME, SUPPORTED_MODELS[[MODEL_NAME]]$provider))

# identify tlg r files - using here package for path management
tlg_r_names <- list.files(path = here::here("submission/programs"), pattern = "^tlf.*\\.r$", full.names = TRUE)

# Print found files
print("Found TLG files:")
print(tlg_r_names)
```

### Approach 1:

Extract information from R code

```{r}
tlg_var_dat_pair <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_var_dat_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_filter <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_filter_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_output <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_output_code, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_parse_dat_var <- sapply(tlg_var_dat_pair, function(i)
  llm_call(paste(prompt_parse_dat_var, i), 
           model = MODEL_NAME))

tab.out <- cbind(tlg_r_names, tlg_output, tlg_parse_dat_var, tlg_filter)
colnames(tab.out) <- c("script","output","Analysis Datasets & Variables","selection criteria")
knitr::kable(tab.out)
```

### Approach 2:

First write a description from R code, then extract information from the description - seem to have more formatting issues / information mixup

```{r eval=FALSE}
# NOT RUN
tlg_extraction <- sapply(tlg_r_names, function(i)
  llm_call(paste(prompt_tlg_code_extraction, paste(readLines(i), collapse = " ")), 
           model = MODEL_NAME))

tlg_var_dat_pair2 <- sapply(tlg_extraction, function(i)
  llm_call(paste(prompt_var_dat_para, i), 
           model = MODEL_NAME))

tlg_filter2 <- sapply(tlg_extraction, function(i)
  llm_call(paste(prompt_filter_para, i), 
           model = MODEL_NAME))

tlg_output2 <- sapply(tlg_extraction, function(i)
  llm_call(paste(prompt_output_para, i), 
           model = MODEL_NAME), simplify = F)

tlg_parse_dat_var2 <- sapply(tlg_var_dat_pair2, function(i)
  llm_call(paste(prompt_parse_dat_var, i), 
           model = MODEL_NAME))

tab.out2 <- cbind(tlg_r_names, tlg_output2, tlg_parse_dat_var2, tlg_filter2)
tab.out3 <- apply(tab.out2, c(1, 2), function(x) gsub("\n", ";", x))
colnames(tab.out3) <- c("script","output","Analysis Datasets & Variables","selection criteria")
knitr::kable(tab.out3)
```

## read in variable descirptions

These information can be used in section 3.1

# Automation block 2: ADaM generation informtion proprocessing

TBD

# Automation block 3: R env information preprocessing

TBD

# insert information into ADRG template